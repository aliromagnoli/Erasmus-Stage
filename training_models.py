# -*- coding: utf-8 -*-
"""Training_models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PPsFOvrUiWinbszvytz9Uh5C6iktSS0g

# Training models

## Libraries
"""

import os
import ResIndex

#import methods2_nn
import methods_evaluation_metrics
import pandas as pd
from sklearn.model_selection import train_test_split
import random
import spacy
spacy.cli.download("en_core_web_sm")

approach = 1

"""## Data preparation"""

path = os.getcwd() + "\datasets\preprocessed datasets"

#import of the preprocessed datasets
dataset = dict()
dataset["ace"] = pd.read_csv(path + "\preprocessed_ace.csv", index_col=0)
dataset["copd"] = pd.read_csv(path + "\preprocessed_copd.csv", index_col=0)
dataset["ppi"] = pd.read_csv(path + "\preprocessed_ppi.csv", index_col=0)

#random seed for reproducibility
SEED = [1009, 2839] #, 516, 2383, 273, 1625, 1324, 2791, 7, 1928] #for cross-validation

#parameters
clean_text = True
TRAIN_SIZE = 0.5
SAMPLING = 1
K = 95

"""## Training with cross validation"""

#creating dataset to save results

res = pd.DataFrame()

#creating dataset to save predictions

pred = pd.DataFrame() #ML predictions
all_epochs_res = pd.DataFrame() #NN predictions
best_train_preds_dict = {} #NN predictions
best_valid_preds_dict = {} #NN predictions
test_preds_dict = {} #NN predictions

import methods1_ml
for i in dataset:

  print("\nDATASET", i, "\n")
  j = 0 # fold number

  if approach == 2:
      dataset[i] = methods2_nn.maintain_only_text_label(dataset[i], clean_text)

  #cross validation k folds
  for h in range(len(SEED)):

    j += 1
    print("\nSplit number", j, "\n")

    #train-test split
    set1, set2 = train_test_split(dataset[i],
                                  train_size=TRAIN_SIZE,
                                  random_state=random.seed(SEED[0]),
                                  shuffle=True,
                                  stratify=dataset[i]['label'])

    for k in range(2): #swapping train and test (kx2 cross-validation)

        res_index = ResIndex.ResIndex(i, j, k+1)

        if k == 0:

            if approach == 1:
                X_train, y_train, X_test, y_test = methods1_ml.final_ml_preprocessing(set1, set2)
            elif approach == 2:
                train_data, valid_data, test_data = methods2_nn.final_nn_preprocessing(set1, set2, SEED[0], SAMPLING)
            print("First iteration")

        else:

            if approach == 1:
                X_train, y_train, X_test, y_test = methods1_ml.final_ml_preprocessing(set2, set1)
            elif approach == 2:
                train_data, valid_data, test_data = methods2_nn.final_nn_preprocessing(set1, set2, SEED[0], SAMPLING)
            print("\nSecond iteration")


        if approach == 1:
            methods1_ml.ml_training(X_train, y_train, X_test, pd.DataFrame(y_test), res_index)
        elif approach == 2:
            pred, res = methods2_nn.nn_training(train_data, valid_data, test_data, dataset[i], res_index, res)


#computing avg and std of metrics
avg_res = methods_evaluation_metrics.compute_avg_std(res)

#computing rank-based metrics
for l in range(len(pred)):
  data = methods_evaluation_metrics.arrange_predictions_and_targets(pred, l)
  avg_res = methods_evaluation_metrics.update_results(data, pred.loc[l, "df"], pred.loc[l, "model"], avg_res)

#saving results in a csv file
path = os.getcwd() + "/results"
with open(path + "/ml_results_preprocessing2.csv", 'w', encoding = 'utf-8-sig') as f:
  res.to_csv(f)
with open(path + "/ml_avg_results_preprocessing2.csv", 'w', encoding = 'utf-8-sig') as f:
  avg_res.to_csv(f)

