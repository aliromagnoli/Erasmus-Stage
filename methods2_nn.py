# -*- coding: utf-8 -*-
"""Neural_Network_approach.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sjiUlTvkekRvPAulSPUpT4MQIhgpv1lk

# Neural Network approach with RNN
"""


"""## Libraries and data import"""

import methods_data_import_and_preprocessing as pr
import methods_evaluation_metrics as eval
import spacy

spacy.cli.download("en_core_web_sm")
import pandas as pd
import torch
import random
torch.cuda.empty_cache()
from torchtext.legacy import data
from torchtext.legacy.data import Dataset, Example
import torch.nn as nn
import torch.optim as optim
import time
from IPython.display import display

# PARAMETERS

torch.manual_seed(1009)
torch.backends.cudnn.deterministic = True

# FIELD: how the data should be processed
TEXT = data.Field(tokenize='spacy', tokenizer_language='en_core_web_sm', include_lengths=True)
LABEL = data.LabelField(dtype=torch.float)
fields = {'label': LABEL, "text": TEXT}

# bucket iterator configuration
BATCH_SIZE = 32
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# neural network configuration
EMBEDDING_DIM = 100  # size of the dense word vectors
HIDDEN_DIM = 256  # size of the hidden states (usually 100-500)
OUTPUT_DIM = 1  # number of classes
N_LAYERS = 5
BIDIRECTIONAL = True
DROPOUT = 0.5
N_EPOCHS = 2


def maintain_only_text_label(df, clean_text):
    # removal and renaming of columns
    if clean_text:
        df.drop(labels=df.columns.difference(['label', "text_clean"]), axis=1, inplace=True)
        df.rename(columns={'text_clean': 'text'}, inplace=True)
    else:
        df.drop(df.columns.difference(['label', "text"]), 1, inplace=True)

    print(df.shape)
    return df  # dataset with "label and text"


def final_nn_preprocessing(train, test, sampling, seed):

    # OVERSAMPLING ON TRAINING SET
    X_ros, y_ros = pr.oversampling(train["text"].values.reshape(-1, 1), train["label"].values, sampling, seed)

    # creation of oversampled training set
    oversampled_train = pd.DataFrame(X_ros, columns=["text"])
    oversampled_train["label"] = y_ros

    # PYTORCH DATASET
    train_data = DataFrameDataset(oversampled_train, fields)
    df = DataFrameDataset(test, fields)

    # TEST-VAL SPLIT
    test_data, valid_data = df.split(split_ratio=0.8, stratified=True, strata_field='label', random_state=random.seed(seed))

    # VOCABULARY
    TEXT.build_vocab(train_data, vectors="glove.6B.100d", unk_init=torch.Tensor.normal_)
    LABEL.build_vocab(train_data)

    """
    print("Label distribution in training set:", Counter(y_ros), "\n")

    print(f'Number of training examples: {len(train_data)}')
    print(f'Number of testing examples: {len(test_data)}')
    print(f'Number of validation examples: {len(valid_data)}\n')

    print("Training example:", vars(train_data.examples[0]), "\n")

    print(f"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}")
    print(f"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\n")

    print("Most common words:", TEXT.vocab.freqs.most_common(20))

    # see the vocabulary directly using either stoi (string to int) or itos (int to string)
    print(TEXT.vocab.itos[:10])

    # check the labels, ensuring 0 is for negative and 1 is for positive, LABEL.vocab.stoi = {1:1, 0:0}
    print(LABEL.vocab.stoi)
    """

    return train_data, valid_data, test_data


class DataFrameDataset(Dataset):
    """Class for using pandas DataFrames as a datasource"""

    def __init__(self, examples, fields, filter_pred=None):
        """
        Create a dataset from a pandas dataframe of examples and Fields
        - examples pd.DataFrame: DataFrame of examples
        - fields {str: Field}: The Fields to use in this tuple.
        - filter_pred (callable or None): use only exanples for which filter_pred(example) is true,
            or use all examples if None.
        """
        self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()
        if filter_pred is not None:
            self.examples = filter(filter_pred, self.examples)
        self.fields = dict(fields)
        # Unpack field tuples
        for n, f in list(self.fields.items()):
            if isinstance(n, tuple):
                self.fields.update(zip(n, f))
                del self.fields[n]


class SeriesExample(Example):
    """Class to convert a pandas Series to an Example"""

    @classmethod
    def fromSeries(cls, data, fields):
        return cls.fromdict(data.to_dict(), fields)

    @classmethod
    def fromdict(cls, data, fields):
        ex = cls()

        for key, field in fields.items():
            if key not in data:
                raise ValueError("Specified key {} was not found in "
                                 "the input data".format(key))
            if field is not None:
                setattr(ex, key, field.preprocess(data[key]))
            else:
                setattr(ex, key, data[key])
        return ex


class RNN(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,
                 bidirectional, dropout, pad_idx):
        super().__init__()

        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)

        self.rnn = nn.LSTM(embedding_dim,  # LSTM layer
                           hidden_dim,
                           num_layers=n_layers,
                           bidirectional=bidirectional,
                           dropout=dropout)

        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # linear layer (hidden_dim * 2 because it's bidirectional)

        self.dropout = nn.Dropout(dropout)  # dropout layer

    def forward(self, text, text_lengths):  # text_lengths is needed to be able to use packed padded sequences

        # text = [sent len, batch size] (tensor)
        # text is a batch of sentences, each having each word converted into a one-hot vector

        # embedded = [sent len, batch size, emb dim] (tensor)
        embedded = self.dropout(self.embedding(text))

        # PACK SEQUENCE: before we pass our embeddings to the RNN, we need to pack them
        # this will cause our RNN to only process the non-padded elements of a sequence
        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))

        # the RNN will then return packed_output (a packed sequence) as well as the hidden and cell states (both of which are tensors)
        packed_output, (hidden, cell) = self.rnn(packed_embedded)
        # so LSTM returns the output and a tuple of the final hidden state and the final cell state

        # hidden = [num layers * num directions, batch size, hid dim]
        # cell = [num layers * num directions, batch size, hid dim]

        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers and apply dropout
        # hidden = [batch size, hid dim * num directions]
        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))

        # the last hidden state, hidden, is fed through the linear layer to produce a prediction
        return self.fc(hidden)


def set_criterion(df):
    # CRITERION: loss function
    # chosen loss function: binary cross entropy with logits
    weights = [1 - (len(df[df["label"] == 0]) / df.shape[0])]
    weight = torch.FloatTensor(weights)
    criterion = nn.BCEWithLogitsLoss(weight=weight)
    # place the model on the GPU (if we have one)
    return criterion.to(device)


"""## Model training"""

"""
def count_parameters(model):

  Function that tells how many trainable parameters the model has 
  so we can compare the number of parameters across different models.

  return sum(p.numel() for p in model.parameters() if p.requires_grad)
"""


def model_creation(res_index, dataset):

    # CREATION OF RNN CLASS' INSTANCE

    INPUT_DIM = len(TEXT.vocab)  # input dimension: dimension of the one-hot vectors (equal to the vocabulary size)
    PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]  # get the pad token index from the vocabulary

    model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)
    # print(f'The model has {count_parameters(model):,} trainable parameters\n')

    # USE OF WORD EMBEDDING IN THE MODEL

    pretrained_embeddings = TEXT.vocab.vectors  # retrieve the embeddings from the field's vocab
    # print("Pretrained embeddings shape:", pretrained_embeddings.shape, "\n")

    model.embedding.weight.data.copy_(pretrained_embeddings)  # replace weights with pre-trained embeddings

    # INITIALIZATION OF <UNK> AND <PAD> TO ALL ZEROS

    # get the index of the <unk> tokens
    UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]

    # initialize <unk> and <pad> tokens to all zeros
    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)
    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)

    # check that the first two rows of the embedding weights matrix have been set to zeros
    # print(model.embedding.weight.data)

    # TRAINING PARAMETERS

    # OPTIMIZER: Adam
    optimizer = optim.Adam(model.parameters())

    # CRITERION: BCE
    criterion = set_criterion(dataset)

    # place the model on the GPU (if we have one)
    model = model.to(device)

    return model, criterion, optimizer


def train_model(model, iterator, criterion, optimizer, epoch, res_index): # iterates over all examples, one batch at a time
    epoch_loss = 0
    pred = []
    target = []

    model.train()  # put the model in "training mode", which turns on dropout and batch normalization

    for batch in iterator:

        optimizer.zero_grad()  # we first zero the gradients

        text, text_lengths = batch.text  # separate batch.text

        # feed the batch of sentences, text, and their lengths, text_lengths into the model
        predictions = model(text, text_lengths).squeeze(1)
        # squeeze is needed as the predictions are initially size [batch size, 1]
        pred.append(predictions.cpu())
        target.append(batch.label.cpu())

        # computation of loss
        loss = criterion(predictions, batch.label)

        loss.backward()  # calculate the gradient of each parameter
        optimizer.step()  # update the parameters using the gradients and optimizer algorithm

        epoch_loss += loss.item()


    pred_df = eval.arrange_predictions_and_targets([item.detach().numpy() for sublist in pred for item in sublist],
                                                   [item.detach().numpy() for sublist in target for item in sublist])

    row = {"df": res_index.get_df(),
           "model": "LSTM",
           "set": "train",
           "fold": res_index.get_fold(),
           "iteration": res_index.get_iter(),
           "epoch": epoch,
           "loss": epoch_loss}

    row = eval.evalmetrics(pred_df["target"], pred_df["prediction"], [0, 1], row)

    return row, pred_df


def evaluate_model(model, iterator, criterion, epoch, res_index, set_type):  # similar to train, without the the update of the parameters

    epoch_loss = 0
    pred = []
    target = []

    model.eval()  # puts the model in "evaluation mode", which turns off dropout and batch normalization

    with torch.no_grad():  # in order to not calculate gradients

        for batch in iterator:
            text, text_lengths = batch.text  # separate batch.text

            predictions = model(text, text_lengths).squeeze(1)
            pred.append(predictions.cpu())
            target.append(batch.label.cpu())

            loss = criterion(predictions, batch.label)

            epoch_loss += loss.item()

    pred_df = eval.arrange_predictions_and_targets([item.detach().numpy() for sublist in pred for item in sublist],
                                                   [item.detach().numpy() for sublist in target for item in sublist])

    row = {"df": res_index.get_df(),
           "model": "LSTM",
           "set": set_type,
           "fold": res_index.get_fold(),
           "iteration": res_index.get_iter(),
           "epoch": epoch,
           "loss": epoch_loss}

    row = eval.evalmetrics(pred_df["target"], pred_df["prediction"], [0, 1], row)

    return row, pred_df


def epoch_time(start_time, end_time):
    """
    Returns how long an epoch takes, in order to compare training times between models
    """
    elapsed_time = end_time - start_time
    elapsed_mins = int(elapsed_time / 60)
    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))
    return elapsed_mins, elapsed_secs


def nn_training(train_data, valid_data, test_data, res_index, dataset, res, epochs_res, best_tr_pred_dict, best_v_pred_dict, te_pred_dict):

    # CREATION OF ITERATORS
    train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(
        (train_data, valid_data, test_data),
        batch_size=BATCH_SIZE,
        device=device,
        sort_key=lambda x: len(x.text),
        sort_within_batch=True)

    model, criterion, optimizer = model_creation(res_index, dataset)

    """ TRAINING """

    best_val_results = {"loss": 1}
    tr_pred_dict = {}
    v_pred_dict = {}

    for epoch in range(N_EPOCHS):

        start_time = time.time()

        # training
        train_results, train_preds = train_model(model = model,
                                                 iterator = train_iterator,
                                                 criterion = criterion,
                                                 optimizer = optimizer,
                                                 epoch = epoch+1,
                                                 res_index = res_index)
        tr_pred_dict.update({epoch+1: train_preds})

        # evaluation
        val_results, val_preds = evaluate_model(model = model,
                                                iterator = valid_iterator,
                                                criterion = criterion,
                                                epoch = epoch+1,
                                                res_index = res_index,
                                                set_type = "validation")
        v_pred_dict.update({epoch + 1: val_preds})

        # computation of time
        end_time = time.time()
        epoch_mins, epoch_secs = epoch_time(start_time, end_time)

        # at each epoch, if the validation loss is the best seen so far,
        # we'll save the parameters of the model and then, after training has finished,
        # we'll use that model on the test set
        if val_results["loss"] < best_val_results["loss"]:
            best_train_results = train_results
            best_val_results = val_results
            torch.save(model.state_dict(), 'tut2-model.pt')

        # results for each epoch
        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')
        print(f'\tTrain Loss: {train_results["loss"]} | Train Acc: {train_results["acc"]}% | Train Recall: {train_results["recall"]}% | Train Precision: {train_results["precision"]}% | Train F2: {train_results["f2"]}% | Train F3: {train_results["f3"]}%')
        print(f'\t Val. Loss: {val_results["loss"]} |  Val. Acc: {val_results["acc"]}% | Val. Recall: {val_results["recall"]}% | Val. Precision: {val_results["precision"]}% | Val. F2: {val_results["f2"]}% | Val. F3: {val_results["f3"]}%')

        epochs_res = epochs_res.append(train_results, ignore_index=True)
        epochs_res = epochs_res.append(val_results, ignore_index=True)

    # RESULTS ON TRAIN AND VALIDATION SET WITH THE BEST MODEL

    print(f'Epoch: {best_train_results["epoch"]}')
    print(
        f'\tTrain Loss: {best_train_results["loss"]} | Train Acc: {best_train_results["acc"]}% | Train Recall: {best_train_results["recall"]}% | Train Precision: {best_train_results["precision"]}% | Train F2: {best_train_results["f2"]}% | Train F3: {best_train_results["f3"]}%')
    print(
        f'\tVal. Loss: {best_val_results["loss"]} |  Val. Acc: {best_val_results["acc"]}% | Val. Recall: {best_val_results["recall"]}% | Val. Precision: {best_val_results["precision"]}% | Val. F2: {best_val_results["f2"]}% | Val. F3: {best_val_results["f3"]}%')

    best_tr_pred_dict.update({res_index.get_iter(): tr_pred_dict[best_train_results["epoch"]]})
    best_v_pred_dict.update({res_index.get_iter(): v_pred_dict[best_train_results["epoch"]]})

    # RESULTS ON TEST SET

    # test loss and accuracy (using parameters that gave the best validation loss)
    model.load_state_dict(torch.load('tut2-model.pt'))
    test_results, test_preds = evaluate_model(model = model,
                                              iterator = test_iterator,
                                              criterion = criterion,
                                              epoch = best_train_results["epoch"],
                                              res_index = res_index,
                                              set_type = "test")

    print(
        f'\nTest Loss: {test_results["loss"]} | Test Acc: {test_results["acc"]}% | Test Recall: {test_results["recall"]}% | Test Precision: {test_results["precision"]}% | Test F2: {test_results["f2"]}% | Test F3: {test_results["f3"]}%')

    te_pred_dict.update({res_index.get_iter(): test_preds})

    res = res.append(best_train_results, ignore_index=True)
    res = res.append(best_val_results, ignore_index=True)
    res = res.append(test_results, ignore_index=True)
    epochs_res = epochs_res.append(test_results, ignore_index=True)

    print(epochs_res.shape)
    display(epochs_res.head())

    print(res.shape)
    display(res.head())

    return res
